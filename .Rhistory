library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.test)
vowel.test$y  <- as.factor(vowel.test$y)
str(vowel.test)
vowel.train$y  <- as.factor(vowel.train$y)
str(vowel.train)
set.seed(33833)
library(caret)
mod1 <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
mod2 <- train(y ~ ., method="gbm",data=vowel.train,verbose=FALSE)
mod1
mod2
pred1 <- predict(mod1,vowel.test)
pred2 <- predict(mod2,vowel.train)
confusionMatrix(pred1,vowel.test$y)
confusionMatrix(pred1,vowel.test$y)$overall[1]
confusionMatrix(pred2,vowel.test$y)$overall[1]
pred2 <- predict(mod2,vowel.test)
confusionMatrix(pred2,vowel.test$y)$overall[1]
predDF=data.frame(pred1,pred2,y=vowel.test$y)
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
confusionMatrix(combPred,vowel.test$y)$overall[1]
confusionMatrix(combPred,vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433 )
set.seed(62433)
head(training)
str(training)
mod1 <- train(diagnosis ~ ., method="rf",data=training,verbose=FALSE)
mod2 <- train(diagnosis ~ ., method="gbm",data=training,verbose=FALSE)
mod3 <- train(diagnosis ~ ., method="lda",data=training,verbose=FALSE)
pred1 <- predict(mod1,testing)
pred2 <- predict(mod2,testing)
pred3 <- predict(mod3,testing)
confusionMatrix(pred1,testing$diagnosis)$overall[1]
confusionMatrix(pred2,testing$diagnosis)$overall[1]
confusionMatrix(pred3,testing$diagnosis)$overall[1]
predDF <- data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
combModFit <- train(diagnosis ~.,method="rf",data=predDF)
combPred <- predict(combModFit,predDF)
table(combPred,testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model <- train(CompressiveStrength~ .,data=training,method="lasso")
model
?plot.enet
library(elasticnet)
str(concrete)
object1 <- enet(concrete[,1:8],concrete$CompressiveStrength,lambda=0)
object1 <- enet(concrete(-9),concrete$CompressiveStrength,lambda=0)
object1 <- enet(x=subset(training,select=-c(CompressiveStrength)),y=concrete$CompressiveStrength,lambda=0)
object1 <- enet(x=data.matrix(subset(training,select=-c(CompressiveStrength))),y=concrete$CompressiveStrength,lambda=0)
object1 <- enet(x=data.matrix(training[,1:8]),y=concrete$CompressiveStrength,lambda=0)
str(training)
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
data <- read.csv(file = "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
str(data)
dat <- data
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
?bats
fit  <- bats(tstrain)
plot(forecast(fit))
fit
fcast <- forecast(fit)
fcast
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
install.packages(e1071)
install.packages("e1071")
install.packages("e1071")
library(e1071)
model <- svm(CompressiveStrength ~ ., data = training)
model
pred <- predict.svm(model,testing)
pred <- predict(model,testing)
pred
sqrt(sum((pred-testing$CompressiveStrength)^2))
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testing  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
str(training)
head(training)
dim(training)
dim(testing)
dim(testing)
table(training$user_name,training$classe)
table(training$user_name,training$classe)
summary(training$cvtd_timestamp)
library(lubridate)
summary(ymd(training$cvtd_timestamp))
summary(format(training$cvtd_timestamp,"%Y%M%dd"))
summary(format(training$cvtd_timestamp,"%Y%M%d"))
summary(format(training$cvtd_timestamp,"%Y%M%d"))
summary((training$cvtd_timestamp)
summary(format(training$cvtd_timestamp,"%Y%M%d"))
summary(format(training$cvtd_timestamp,"%Y%m%d"))
summary(format(training$cvtd_timestamp,"%Y %m %d"))
summary(training$cvtd_timestamp)
barplot(training$classe)
heatmap(data.matrix(testing[,8:ncol(testing)-1]),na.rm=TRUE)
@
heatmap(data.matrix(testing[,8:ncol(testing)-1]),na.rm=TRUE)
heatmap(data.matrix(testing[,9:ncol(testing)-1]),na.rm=TRUE)
aux = training[rowSums(!is.na(x))!=0, colSums(!is.na(x))!=0]
aux <-  training[rowSums(!is.na(x))!=0, colSums(!is.na(x))!=0]
library(caret)
set.seed(1)
mod_rf  <- train(classe ~ ., data = training, method = "rf")
data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
validation  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
table(data$user_name,training$classe)
inTrain = createDataPartition(data$classe, p = 3/4)[[1]]
training = data[inTrain, ]
testing = data[-inTrain, ]
nzv <- nearZeroVar(data, saveMetrics= TRUE)
nzv
nzv <- nearZeroVar(data)
dim(data)
data2 <- data[, -nzv]
dim(data2)
inTrain = createDataPartition(data2$classe, p = 3/4)[[1]]
inTrain = createDataPartition(data2$classe, p = 3/4)[[1]]
inTrain = createDataPartition(data2$classe, p = 3/4)[[1]]
pred_tree  <- predict(mod_tree, testing)
data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
validation  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
table(data$user_name,data$classe)
library(caret)
nzv <- nearZeroVar(data)
dim(data)
data2 <- data[, -nzv]
dim(data2)
library(caret)
set.seed(1)
inTrain = createDataPartition(data2$classe, p = 3/4)[[1]]
training = data2[inTrain, ]
testing = data2[-inTrain, ]
dim(training)
dim(testing)
library(caret)
mod_tree <- train(classe ~ ., data = training, method = "rpart")
mod_tree
pred_tree  <- predict(mod_tree, testing)
confusionMatrix(pred_tree, testing$classe)$overall[1]
str(pred_tree)
min(pred_tree)
dim(pred_tree)
pred_tree  <- predict(mod_tree, testing)
pred_tree
confusionMatrix(pred_tree, testing$classe)$overall[1]
dim(testing)
testing$classe
pred_rf  <- predict(mod_rf, testing)
mod_rf   <- train(classe ~ ., data = training, method = "rf")
pred_rf  <- predict(mod_rf, testing)
pred_rf
pred_rf  <- predict(mod_rf, newdata=testing)
pred_rf
mod_rf
dim(training)
dim(testing)
testing[111:114,]
predict
pred_tree  <- predict(mod_tree, testing)
pred_tree
data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", sep = ",", na.strings = c("", "NA"))
validation  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", sep = ",", na.strings = c("", "NA"))
data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", sep = ",", na.strings = c("", "NA"))
validation  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", sep = ",", na.strings = c("", "NA"))
table(data$user_name,data$classe)
library(caret)
nzv <- nearZeroVar(data)
dim(data)
data2 <- data[, -nzv]
dim(data2)
library(caret)
set.seed(1)
inTrain = createDataPartition(data2$classe, p = 3/4)[[1]]
training = data2[inTrain, ]
testing = data2[-inTrain, ]
dim(training)
dim(testing)
library(caret)
mod_tree <- train(classe ~ ., data = training, method = "rpart")
library(caret)
mod_rf   <- train(classe ~ ., data = training, method = "rf")
library(caret)
set.seed(1)
inTrain = createDataPartition(data2$classe, p = 3/4)[[1]]
training = data2[inTrain, ]
testing = data2[-inTrain, ]
data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", sep = ",", na.strings = c("", "NA"))
validation  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", sep = ",", na.strings = c("", "NA"))
table(data$user_name,data$classe)
data <- data[, colSums(is.na(data)) == 0]
validation <- validation[, colSums(is.na(validation)) == 0]
data <- data$classe  #reserve classe
dataRemove <- grepl("^X|timestamp|window", names(data))
data <- data[, !dataRemove]
data2 <- data[, sapply(data, is.numeric)]
data2$classe <- classe
validationRemove <- grepl("^X|timestamp|window", names(validation))
validation <- validation[, !validationRemove]
validation2 <- validation[, sapply(validation, is.numeric)]
data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", sep = ",", na.strings = c("", "NA"))
validation  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", sep = ",", na.strings = c("", "NA"))
table(data$user_name,data$classe)
data <- data[, colSums(is.na(data)) == 0]
validation <- validation[, colSums(is.na(validation)) == 0]
classe <- data$classe  #reserve classe
dataRemove <- grepl("^X|timestamp|window", names(data))
data <- data[, !dataRemove]
data2 <- data[, sapply(data, is.numeric)]
data2$classe <- classe
validationRemove <- grepl("^X|timestamp|window", names(validation))
validation <- validation[, !validationRemove]
validation2 <- validation[, sapply(validation, is.numeric)]
dim(data2)
dim(validation2)
library(caret)
set.seed(1)
inTrain = createDataPartition(data2$classe, p = 3/4)[[1]]
training = data2[inTrain, ]
testing = data2[-inTrain, ]
dim(testing)
dim(training)
library(caret)
mod_tree <- train(classe ~ ., data = training, method = "rpart")
library(caret)
mod_rf   <- train(classe ~ ., data = training, method = "rf")
install.packages("installr")
library(installr)
updateR()
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
library(data.table)
library(dplyr)
library(rgdal)
url <- "http://www.aemet.es/documentos/es/conocermas/recursos_en_linea/publicaciones_y_estudios/publicaciones/Valores_mensuales_1981_2010/Normales_mensuales_1981_2010.zip"
dirData <- "./data"
nameZip <- "download.zip"
nameUnzipped <- "Normales Precipitacion 1981_2010/Normales Precipitacion mensual 1981_2010.txt"
download.file(url=url,destfile = paste0(dirData,"/",nameZip))
unzip(paste0(dirData,"/",nameZip),exdir=dirData)
rawData<- fread(paste0(dirData,"/",nameUnzipped),data.table = FALSE)
rawData <- rawData %>%
na.omit() %>%
mutate (sumrain=Ene+Feb+Mar+Abr+May+Jun+Jul+Ago+Sep+Oct+Nov+Dic)
utms <- SpatialPoints(rawData[, c("x (Uso 30)", "y (Uso 30)")],
proj4string=CRS("+proj=utm +zone=30"))
longlats <- spTransform(utms, CRS("+proj=longlat"))
coord <- coordinates(longlats)
rawData <- rawData %>%
na.omit() %>%
mutate (long=coord[,1], lat=coord[,2])
rainData<- rawData %>%
select(
Ind = Ind,
Watershed = Cuenca,
Station = starts_with("Nombre"),
Province = Provincia,
Yearrain = sumrain,
Jan = Ene,
Feb = Feb,
Mar = Mar,
Apr = Abr,
May = May,
Jun = Jun,
Jul = Jul,
Aug = Ago,
Sep = Sep,
Oct = Oct,
Nov = Nov,
Dec = Dic,
Latitude = lat,
Longitude = long)
provinces<-unique(rainData[[Province]])
provinces<-unique(rainData$Province)
provinces
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
install.packages("DT")
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
head(raindata)
head(rainData)
df <- rainData %>%
filter(
is.null(input$Provinces) | Province %in% input$PRovinces
)
df <- rainData %>%
filter(
is.null("ALICANTE") | Province %in% input$PRovinces
)
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
shiny::runApp('dataprods/dataprod-project')
devtools::install_github('rstudio/rsconnect')
rsconnect::setAccountInfo(name='jnombela',
token='3E8507570AA767FE745297CA7B296FDE',
secret='<SECRET>')
rsconnect::setAccountInfo(name='jnombela',
token='3E8507570AA767FE745297CA7B296FDE',
secret='8M5koJvIa7BfSxJprZEwUt5slU1d11In4mZvqga8')
library(rsconnect)
setwd("~/ZZ PERSONAL/big Data/cursos/coursera/data science specialization/00 - repositorio/dataprods")
rsconnect::deployApp('./dataprod-project')
shiny::runApp('dataprod-project')
setwd("~/ZZ PERSONAL/big Data/cursos/coursera/data science specialization/00 - repositorio/dataprods/dataprod-project")
deployApp()
setwd("~/ZZ PERSONAL/big Data/cursos/coursera/data science specialization/00 - repositorio/dataprods/dataprod-project")
rsconnect::appDependencies()
shiny::runApp()
shiny::runApp()
shiny::runApp()
deployApp(lint=TRUE)
deployApp(lint=TRUE)
library(slidify)
author("project_pitch")
setwd("~/ZZ PERSONAL/big Data/cursos/coursera/data science specialization/00 - repositorio/dataprods")
author("project_pitch")
